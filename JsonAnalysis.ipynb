{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37564biteb60b8ef6de74d438eefe0c53a2cd350",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "cells": [
  {
   "source": [
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 1
  },
  {
   "source": [
    "### data pre-processing -- read data from files - single \n",
    "# json analyis \n",
    "participant= 1\n",
    "fileAdd = './cleanjson/P'+str(participant)+'.json'\n",
    "data = pd.read_json(fileAdd)\n",
    "# print(data['data'])\n",
    "test = json_normalize(data['data'])\n",
    "# print(test)\n",
    "df = pd.DataFrame.from_dict(test, orient='columns')\n",
    "\n",
    "L1 = df.loc[(df['index']<=21)|(df['index']>=24)&(df['index']<=45)]\n",
    "L2 = df.loc[(df['index']>=46)&(df['index']<=99)]\n",
    "L3 = df.loc[(df['index']>=120)&(df['index']<=153)]\n",
    "print(L1.describe())\n",
    "print(L2.describe())\n",
    "print(L3.describe())"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "### data pre-processing -- read data from file - group\n",
    "M1 = []\n",
    "M2 = []\n",
    "M3 = []\n",
    "for p in range(1,15):\n",
    "    fileAdd = './cleanjson/P'+str(p)+'.json'\n",
    "    data = pd.read_json(fileAdd)\n",
    "    test = json_normalize(data['data'])\n",
    "    df = pd.DataFrame.from_dict(test, orient='columns')\n",
    "    L1 = df.loc[(df['index']<=21)|(df['index']>=24)&(df['index']<=45)]\n",
    "    L2 = df.loc[(df['index']>=46)&(df['index']<=99)]\n",
    "    L3 = df.loc[(df['index']>=120)&(df['index']<=153)]  \n",
    "\n",
    "    mean_L1 = L1['score'].mean()\n",
    "    mean_L2 = L2['score'].mean()\n",
    "    mean_L3 = L3['score'].mean()\n",
    "    M1.append(mean_L1)\n",
    "    M2.append(mean_L2)\n",
    "    M3.append(mean_L3)\n",
    "print(M1)\n",
    "print(M2)\n",
    "print(M3)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "### data pre-processing -- data visualization\n",
    "Mean_data = {'L1':M1,\n",
    "'L2':M2,\n",
    "'L3':M3}\n",
    "df_accuracy = pd.DataFrame(Mean_data)\n",
    "print(df_accuracy.mean())\n",
    "fig =plt.figure()\n",
    "df_accuracy.plot()\n",
    "fig =plt.figure()\n",
    "df_accuracy.boxplot(grid=False)"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'M1' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-77189663981a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m### data pre-processing -- data visualization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m Mean_data = {'L1':M1,\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;34m'L2'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mM2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m 'L3':M3}\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMean_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'M1' is not defined"
     ]
    }
   ],
   "metadata": {},
   "execution_count": 2
  },
  {
   "source": [
    "### one way anova  by stats \n",
    "# load packages\n",
    "import scipy.stats as stats\n",
    "d = df_accuracy\n",
    "# stats f_oneway functions takes the groups as input and returns F and P-value\n",
    "fvalue, pvalue = stats.f_oneway(d['L1'], d['L2'], d['L3'])\n",
    "print(fvalue, pvalue)\n",
    "\n",
    "\n",
    "# get ANOVA table as R like output\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "# reshape the d dataframe suitable for statsmodels package \n",
    "d_melt = pd.melt(d.reset_index(), id_vars=['index'], value_vars=['L1', 'L2', 'L3'])\n",
    "# replace column names\n",
    "d_melt.columns = ['index', 'Levels', 'value']\n",
    "# Ordinary Least Squares (OLS) model\n",
    "model = ols('value ~ C(Levels)', data=d_melt).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "anova_table"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "### one way anova and post hoc test  by pingouin \n",
    "import pingouin as pg\n",
    "from pingouin import pairwise_tukey\n",
    "# perform multiple pairwise comparison (Tukey HSD)\n",
    "# for unbalanced (unequal sample size) data, pairwise_tukey uses Tukey-Kramer test\n",
    "anova = d_melt.anova(dv='value', between='Levels', detailed=False,effsize='n2')\n",
    "print(anova)\n",
    "print()\n",
    "m_comp = pairwise_tukey(data=d_melt, dv='value', between='Levels')\n",
    "print(m_comp)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "### within subjects data arrangement \n",
    "subject = range(1,15)\n",
    "L1_fill = np.full((14),1)\n",
    "data1 = {'Subjects':subject,'Levels':L1_fill,'Accuracy':M1}\n",
    "df_r = pd.DataFrame(data1)\n",
    "# print(df_r)\n",
    "L1_fill = np.full((14),2)\n",
    "data2 = {'Subjects':subject,'Levels':L1_fill,'Accuracy':M2}\n",
    "df_r2 = pd.DataFrame(data2)\n",
    "df_all = df_r.append(df_r2,ignore_index=True)\n",
    "# print(df_r2)\n",
    "L1_fill = np.full((14),3)\n",
    "data3 = {'Subjects':subject,'Levels':L1_fill,'Accuracy':M3}\n",
    "df_r3 = pd.DataFrame(data3)\n",
    "df_all  = df_all.append(df_r3,ignore_index=True)\n",
    "print(df_all)"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "### within subjects data visualization \n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.pointplot(data=df_all, x='Levels', y='Accuracy',dodge=True, capsize=.1, errwidth=1 )"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "### repeated measure anova by pingouin\n",
    "\n",
    "import pingouin as pg\n",
    "# Compute the two-way mixed-design ANOVA\n",
    "aov = pg.rm_anova(dv='Accuracy', within='Levels', subject='Subjects', data=df_all,effsize='n2')\n",
    "\n",
    "# Pretty printing of ANOVA summary\n",
    "pg.print_table(aov)\n"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "source": [
    "from pingouin import friedman, read_dataset\n",
    "\n",
    "friedman(dv='Accuracy', within='Levels', subject='Subjects', data=df_all)\n"
   ],
   "cell_type": "code",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          Source  ddof1         Q     p-unc\nFriedman  Levels      2  2.714286  0.257395",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>ddof1</th>\n      <th>Q</th>\n      <th>p-unc</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Friedman</th>\n      <td>Levels</td>\n      <td>2</td>\n      <td>2.714286</td>\n      <td>0.257395</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "metadata": {},
   "execution_count": 14
  },
  {
   "source": [
    "## old methods \n",
    "\n",
    "# from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "# #perform the repeated measures ANOVA\n",
    "# print(AnovaRM(data=df_all, depvar='Accuracy', subject='Subjects', within=['Levels']).fit())"
   ],
   "cell_type": "code",
   "outputs": [],
   "metadata": {},
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg\n",
    "L12 = allFeaturers.loc[(allFeaturers['Levels']==1)|(allFeaturers['Levels']==2)]\n",
    "L13 = allFeaturers.loc[(allFeaturers['Levels']==1)|(allFeaturers['Levels']==3)]\n",
    "L23 = allFeaturers.loc[(allFeaturers['Levels']==2)|(allFeaturers['Levels']==3)]\n",
    "\n",
    "pg.wilcoxon(L12['su'],L12[''], tail='two-sided')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}